{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ubermovement-model",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2o2k7LMSB-B",
        "colab_type": "text"
      },
      "source": [
        "## Modeling driving transit times in Seattle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8l-X0roFSjND",
        "colab_type": "text"
      },
      "source": [
        "This notebook uses driving data collected from [movement.uber.com](https://movement.uber.com) and distance data calculated from an AWS-hosted [OSRM server](http://project-osrm.org/) to predict transit times. See preprocessing notebook for data preparation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZWmGG73TKcl",
        "colab_type": "text"
      },
      "source": [
        "### Mount Google drive as storage\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFYqV37Rfy7D",
        "colab_type": "code",
        "outputId": "7ae1f1c6-04b0-4e1b-d46e-b08c66849734",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhexrFOqUz4p",
        "colab_type": "text"
      },
      "source": [
        "### Import modules\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpErUOrBiHlM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "from pprint import pprint\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_extraction import FeatureHasher\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn import metrics\n",
        "\n",
        "from fastai.tabular import *\n",
        "\n",
        "from keras.optimizers import Adadelta\n",
        "from keras.models import Sequential\n",
        "from keras.models import model_from_json\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras import regularizers\n",
        "\n",
        "import json\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqkDzZruo4z5",
        "colab_type": "text"
      },
      "source": [
        "### Load csv with driving and OSRM distance data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VejHqVMxfZ5C",
        "colab_type": "code",
        "outputId": "e83be20b-8085-4d75-fa65-1257c1739cae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# load csv as dataframe\n",
        "path = Path('/content/gdrive/My Drive/Python/ubermovement/data')\n",
        "df = pd.read_csv(path/'df3_with_distances_final.csv')\n",
        "\n",
        "# preview the dataframe\n",
        "df.head()"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>sourceid</th>\n",
              "      <th>dstid</th>\n",
              "      <th>dow</th>\n",
              "      <th>mean_travel_time</th>\n",
              "      <th>standard_deviation_travel_time</th>\n",
              "      <th>geometric_mean_travel_time</th>\n",
              "      <th>geometric_standard_deviation_travel_time</th>\n",
              "      <th>src_lat</th>\n",
              "      <th>src_lon</th>\n",
              "      <th>dst_lat</th>\n",
              "      <th>dst_lon</th>\n",
              "      <th>distance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>719</td>\n",
              "      <td>27</td>\n",
              "      <td>3</td>\n",
              "      <td>1670.75</td>\n",
              "      <td>643.48</td>\n",
              "      <td>1577.05</td>\n",
              "      <td>1.38</td>\n",
              "      <td>47.870603</td>\n",
              "      <td>-122.203015</td>\n",
              "      <td>47.730525</td>\n",
              "      <td>-122.332923</td>\n",
              "      <td>14.540743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>365</td>\n",
              "      <td>149</td>\n",
              "      <td>5</td>\n",
              "      <td>1073.65</td>\n",
              "      <td>480.03</td>\n",
              "      <td>982.73</td>\n",
              "      <td>1.51</td>\n",
              "      <td>47.685120</td>\n",
              "      <td>-122.349925</td>\n",
              "      <td>47.622924</td>\n",
              "      <td>-122.324658</td>\n",
              "      <td>5.502815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>775</td>\n",
              "      <td>717</td>\n",
              "      <td>3</td>\n",
              "      <td>1617.82</td>\n",
              "      <td>226.10</td>\n",
              "      <td>1601.29</td>\n",
              "      <td>1.16</td>\n",
              "      <td>48.085921</td>\n",
              "      <td>-122.174539</td>\n",
              "      <td>47.806039</td>\n",
              "      <td>-122.246657</td>\n",
              "      <td>22.603614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>365</td>\n",
              "      <td>389</td>\n",
              "      <td>6</td>\n",
              "      <td>413.17</td>\n",
              "      <td>164.40</td>\n",
              "      <td>386.37</td>\n",
              "      <td>1.43</td>\n",
              "      <td>47.685120</td>\n",
              "      <td>-122.349925</td>\n",
              "      <td>47.706727</td>\n",
              "      <td>-122.366497</td>\n",
              "      <td>2.244150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>379</td>\n",
              "      <td>249</td>\n",
              "      <td>6</td>\n",
              "      <td>1379.37</td>\n",
              "      <td>384.10</td>\n",
              "      <td>1334.59</td>\n",
              "      <td>1.28</td>\n",
              "      <td>47.386275</td>\n",
              "      <td>-122.231370</td>\n",
              "      <td>47.632713</td>\n",
              "      <td>-122.173700</td>\n",
              "      <td>19.829247</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  sourceid  dstid  ...    dst_lat     dst_lon   distance\n",
              "0           0       719     27  ...  47.730525 -122.332923  14.540743\n",
              "1           1       365    149  ...  47.622924 -122.324658   5.502815\n",
              "2           2       775    717  ...  47.806039 -122.246657  22.603614\n",
              "3           3       365    389  ...  47.706727 -122.366497   2.244150\n",
              "4           4       379    249  ...  47.632713 -122.173700  19.829247\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tx3Vr8jHHofP",
        "colab_type": "text"
      },
      "source": [
        "#### Clean up data using conclusions from proprocessing analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1x8NCKeH11b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# drop extra index column and a highly correlated/redundant travel time column\n",
        "df = df.drop(['Unnamed: 0', 'geometric_mean_travel_time'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YrV-6FZI7le",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "b10c867a-09a2-438e-93cc-8bce9d44bf93"
      },
      "source": [
        "# drop a few rows with nan\n",
        "count_nan = np.count_nonzero(df.isnull().values)\n",
        "print('{} missing values in dataset containing {} rows\\n'.format(count_nan, len(df)))\n",
        "if count_nan:\n",
        "  print(df.isnull().sum())\n",
        "  \n",
        "# since distance is an important predictor of 'mean_travel_time' and only a few rows are missing, drop them\n",
        "print('\\nDropping rows with nan:')\n",
        "df.dropna(inplace=True)\n",
        "count_nan = np.count_nonzero(df.isnull().values)\n",
        "print('{} missing values in dataset containing {} rows'.format(count_nan, len(df)))"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5 missing values in dataset containing 540004 rows\n",
            "\n",
            "sourceid                                    0\n",
            "dstid                                       0\n",
            "dow                                         0\n",
            "mean_travel_time                            0\n",
            "standard_deviation_travel_time              0\n",
            "geometric_standard_deviation_travel_time    0\n",
            "src_lat                                     0\n",
            "src_lon                                     0\n",
            "dst_lat                                     0\n",
            "dst_lon                                     0\n",
            "distance                                    5\n",
            "dtype: int64\n",
            "\n",
            "Dropping rows with nan:\n",
            "0 missing values in dataset containing 539999 rows\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rj18tPu-JHCi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "b1dbbacb-b19e-44e0-9b0d-eb1fbf786c76"
      },
      "source": [
        "# drop lat/lon columns (use 'sourceid' and 'distid')\n",
        "df = df.drop(['src_lat','src_lon','dst_lat', 'dst_lon'], axis=1)\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sourceid</th>\n",
              "      <th>dstid</th>\n",
              "      <th>dow</th>\n",
              "      <th>mean_travel_time</th>\n",
              "      <th>standard_deviation_travel_time</th>\n",
              "      <th>geometric_standard_deviation_travel_time</th>\n",
              "      <th>distance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>719</td>\n",
              "      <td>27</td>\n",
              "      <td>3</td>\n",
              "      <td>1670.75</td>\n",
              "      <td>643.48</td>\n",
              "      <td>1.38</td>\n",
              "      <td>14.540743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>365</td>\n",
              "      <td>149</td>\n",
              "      <td>5</td>\n",
              "      <td>1073.65</td>\n",
              "      <td>480.03</td>\n",
              "      <td>1.51</td>\n",
              "      <td>5.502815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>775</td>\n",
              "      <td>717</td>\n",
              "      <td>3</td>\n",
              "      <td>1617.82</td>\n",
              "      <td>226.10</td>\n",
              "      <td>1.16</td>\n",
              "      <td>22.603614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>365</td>\n",
              "      <td>389</td>\n",
              "      <td>6</td>\n",
              "      <td>413.17</td>\n",
              "      <td>164.40</td>\n",
              "      <td>1.43</td>\n",
              "      <td>2.244150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>379</td>\n",
              "      <td>249</td>\n",
              "      <td>6</td>\n",
              "      <td>1379.37</td>\n",
              "      <td>384.10</td>\n",
              "      <td>1.28</td>\n",
              "      <td>19.829247</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sourceid  dstid  ...  geometric_standard_deviation_travel_time   distance\n",
              "0       719     27  ...                                      1.38  14.540743\n",
              "1       365    149  ...                                      1.51   5.502815\n",
              "2       775    717  ...                                      1.16  22.603614\n",
              "3       365    389  ...                                      1.43   2.244150\n",
              "4       379    249  ...                                      1.28  19.829247\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-6bM6yVhyOp",
        "colab_type": "code",
        "outputId": "6f2317c8-2bfd-4331-b640-753ca81ef16e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# check data types\n",
        "df.dtypes"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sourceid                                      int64\n",
              "dstid                                         int64\n",
              "dow                                           int64\n",
              "mean_travel_time                            float64\n",
              "standard_deviation_travel_time              float64\n",
              "geometric_standard_deviation_travel_time    float64\n",
              "distance                                    float64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OL4dsRskpp4j",
        "colab_type": "text"
      },
      "source": [
        "### Baseline models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rc5Xf1rluWNm",
        "colab_type": "text"
      },
      "source": [
        "#### Median value prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyChK7Ycp3gg",
        "colab_type": "code",
        "outputId": "11d2aa65-beea-4f6d-8599-19646a3d4787",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Make predictions using median value for trip time\n",
        "\n",
        "# get array of travel times and split into 'training' and testing sets\n",
        "travel_times = df['mean_travel_time'].values\n",
        "yTrain, yTest = train_test_split(travel_times, test_size=0.2, random_state=42)\n",
        "\n",
        "# get median value of travel times and find MAE of test set\n",
        "prediction = np.median(yTrain)\n",
        "abs_err = abs(yTest - prediction)\n",
        "mae_med = np.mean(abs_err)\n",
        "\n",
        "print('Mean Absolute Error using median prediction: {}'.format(round(mae_med, 2)))"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Absolute Error using median prediction: 446.02\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbgg-u04ubef",
        "colab_type": "text"
      },
      "source": [
        "#### Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgKVpIgzLZKk",
        "colab_type": "code",
        "outputId": "9389c970-f997-4be5-aa46-ee3cb82eb65c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Multivariate Linear Regression\n",
        "\n",
        "# define categorical and numeric features\n",
        "cat_feat = ['sourceid', 'dstid', 'dow']\n",
        "num_feat = ['distance']\n",
        "cat_hash = [col + '_hash' for col in cat_feat]\n",
        "\n",
        "# there are too many categorical values to one hot encode (curse of dimensionality)\n",
        "# use hash trick instead\n",
        "\n",
        "df_hash = df.copy()\n",
        "max_size = 100\n",
        "\n",
        "fh = FeatureHasher(n_features=max_size, input_type='string')\n",
        "\n",
        "# hash categorical features and add to df_hash\n",
        "for i in range(len(cat_feat)):\n",
        "  feat_hash = fh.fit_transform( df_hash[cat_feat[i]].astype(str) )  # hash of feature\n",
        "  cols = [cat_feat[i] + 'h' + str(j) for j in range(max_size)]      # create names for hash columns\n",
        "  df_temp = pd.DataFrame(feat_hash.toarray(), columns=cols)         # create temp dataframe of hash\n",
        "  df_hash = pd.concat([df_hash, df_temp], axis=1)                   # append to main dataframe\n",
        "\n",
        "# drop columns used for hashing\n",
        "df_hash.drop(cat_feat, axis=1, inplace=True)\n",
        "\n",
        "# feature hashing creates several nan rows; since there are only a few, just remove them\n",
        "print('{} nan values in target\\n'.format(np.sum(np.isnan(df_hash['mean_travel_time']))))\n",
        "print('Removing nan rows:')\n",
        "df_hash.dropna(inplace=True)\n",
        "print('{} nan values in target'.format(np.sum(np.isnan(df_hash['mean_travel_time']))))"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5 nan values in target\n",
            "\n",
            "Removing nan rows:\n",
            "0 nan values in target\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bEg8vHxVzNR",
        "colab_type": "code",
        "outputId": "a8067623-6c26-493e-8ac4-5fef28eaad64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# create target and feature arrays from dataframe\n",
        "y = df_hash['mean_travel_time'].values\n",
        "X = df_hash.drop('mean_travel_time', axis=1).values\n",
        "\n",
        "# normalize features\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# split data into training and testing sets\n",
        "xTrain, xTest, yTrain, yTest = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# fit the regression model\n",
        "lr = LinearRegression()\n",
        "lr.fit(xTrain, yTrain)"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDBDRlGpo48h",
        "colab_type": "code",
        "outputId": "2529b3ac-1f7c-4cd9-fad0-e6bf4257591b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# generate predictions on test data and calculate MAE\n",
        "y_pred = lr.predict(xTest)\n",
        "mae_lr = metrics.mean_absolute_error(yTest,y_pred)\n",
        "print('Mean Absolute Error using linear regression: {}'.format(round(mae_lr, 2)))"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Absolute Error using linear regression: 166.03\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tdC95xzu0Al",
        "colab_type": "text"
      },
      "source": [
        "#### Random forest regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7_R5_Siq7p0",
        "colab_type": "code",
        "outputId": "f9e44054-1d3e-46c8-a472-d1d2b22b0642",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# note that we are using 'mse' to optimize since 'mae' is prohibitively slow\n",
        "# see https://github.com/scikit-learn/scikit-learn/issues/9626\n",
        "\n",
        "rfreg = RandomForestRegressor(n_estimators=10, random_state=42, verbose=0, n_jobs=-1)\n",
        "rfreg.fit(xTrain, yTrain)"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
              "                      max_features='auto', max_leaf_nodes=None,\n",
              "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                      min_samples_leaf=1, min_samples_split=2,\n",
              "                      min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
              "                      oob_score=False, random_state=42, verbose=0,\n",
              "                      warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaOLZkj0z8FU",
        "colab_type": "code",
        "outputId": "4c081255-cd29-48b7-aa19-ce3feaa41dc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# generate predictions for test data and calculate MAE\n",
        "y_pred = rfreg.predict(xTest)\n",
        "mae_rf = metrics.mean_absolute_error(yTest, y_pred)\n",
        "print('Mean Absolute Error using random forest: {}'.format(round(mae_rf, 2)))"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Absolute Error using random forest: 93.16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhtGSzR_0_0b",
        "colab_type": "text"
      },
      "source": [
        "#### Random forest grid search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aS52CiIVo56V",
        "colab_type": "code",
        "outputId": "067ec1a8-62ee-44c9-a455-a50e11a28f6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "# Random forest regression fits with the lowest MAE\n",
        "# Try performing a grid search to optimize hyperparameters\n",
        "\n",
        "print('Current RF parameters:\\n')\n",
        "pprint(reg.get_params())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Current RF parameters:\n",
            "\n",
            "{'bootstrap': True,\n",
            " 'criterion': 'mse',\n",
            " 'max_depth': None,\n",
            " 'max_features': 'auto',\n",
            " 'max_leaf_nodes': None,\n",
            " 'min_impurity_decrease': 0.0,\n",
            " 'min_impurity_split': None,\n",
            " 'min_samples_leaf': 1,\n",
            " 'min_samples_split': 2,\n",
            " 'min_weight_fraction_leaf': 0.0,\n",
            " 'n_estimators': 10,\n",
            " 'n_jobs': None,\n",
            " 'oob_score': False,\n",
            " 'random_state': 42,\n",
            " 'verbose': 0,\n",
            " 'warm_start': False}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_im9jB209jq",
        "colab_type": "code",
        "outputId": "8c618b73-d6e7-40fb-9e52-3164db631003",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "# limit hyperparameter options since modeling is slow\n",
        "param_grid = { \n",
        "    'n_estimators': [10, 50],\n",
        "    'max_features': ['sqrt', 'auto'], # 6 total features\n",
        "    'max_depth' : [3, 10, 50]\n",
        "}\n",
        "\n",
        "# perform cross-validated grid search\n",
        "CV_rfr = GridSearchCV(estimator=RandomForestRegressor(), param_grid=param_grid, cv=3, n_jobs=-1, verbose=1)\n",
        "CV_rfr.fit(xTrain, yTrain)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed: 12.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
              "             estimator=RandomForestRegressor(bootstrap=True, criterion='mse',\n",
              "                                             max_depth=None,\n",
              "                                             max_features='auto',\n",
              "                                             max_leaf_nodes=None,\n",
              "                                             min_impurity_decrease=0.0,\n",
              "                                             min_impurity_split=None,\n",
              "                                             min_samples_leaf=1,\n",
              "                                             min_samples_split=2,\n",
              "                                             min_weight_fraction_leaf=0.0,\n",
              "                                             n_estimators='warn', n_jobs=None,\n",
              "                                             oob_score=False, random_state=None,\n",
              "                                             verbose=0, warm_start=False),\n",
              "             iid='warn', n_jobs=-1,\n",
              "             param_grid={'max_depth': [3, 10, 50],\n",
              "                         'max_features': ['sqrt', 'auto'],\n",
              "                         'n_estimators': [10, 50]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRu-W_tpleOU",
        "colab_type": "code",
        "outputId": "a70fff29-1534-46f1-e2c5-ad49d9624688",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# We won't tune hyperparameters further due to long processing time; \n",
        "# the takeaway in this case is that more features/estimators/depth perform better\n",
        "CV_rfr.best_estimator_"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=50,\n",
              "                      max_features='auto', max_leaf_nodes=None,\n",
              "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                      min_samples_leaf=1, min_samples_split=2,\n",
              "                      min_weight_fraction_leaf=0.0, n_estimators=50,\n",
              "                      n_jobs=None, oob_score=False, random_state=None,\n",
              "                      verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-Sbz0DfUEgg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "5984446b-2f4d-4e0e-8704-83d374fe77e3"
      },
      "source": [
        "# the grid search suggests using more estimators\n",
        "rfreg = RandomForestRegressor(n_estimators=50, random_state=42, verbose=0, n_jobs=-1)\n",
        "rfreg.fit(xTrain, yTrain)"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
              "                      max_features='auto', max_leaf_nodes=None,\n",
              "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                      min_samples_leaf=1, min_samples_split=2,\n",
              "                      min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=-1,\n",
              "                      oob_score=False, random_state=42, verbose=0,\n",
              "                      warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmEqq26lIiLW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ec0e14d2-15d6-48eb-83d8-9f4a1aff3f8b"
      },
      "source": [
        "# generate predictions for test data and calculate MAE\n",
        "y_pred = rfreg.predict(xTest)\n",
        "mae_rf_best = metrics.mean_absolute_error(yTest, y_pred)\n",
        "print('Mean Absolute Error using random forest: {} ({}% improvement)'.format(round(mae_rf_best, 2), round((mae_rf - mae_rf_best)/mae_rf*100, 2)))\n"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Absolute Error using random forest: 89.56 (3.86% improvement)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTW9S7AbHshG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "379fb7ff-3601-4527-fe45-de93daebb691"
      },
      "source": [
        "mae_rf_best"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "93.16129371568256"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ma9ANCgYYAue",
        "colab_type": "text"
      },
      "source": [
        "Increasing the number of estimators from 10 to 50 lowers the MAE by ~4% but takes much longer to train. This might be worth it in some cases, but let's next try using neural networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTDIuHAIpks7",
        "colab_type": "text"
      },
      "source": [
        "### Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "545TNcAbpr2_",
        "colab_type": "text"
      },
      "source": [
        "#### Fastai with PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6qCNzuSTQnL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d133d091-a33c-4728-ae50-11611690d2d0"
      },
      "source": [
        "# set up fastai for Google Colab environment\n",
        "!curl -s https://course.fast.ai/setup/colab | bash"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updating fastai...\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQCBxfasb_BZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split dataframe into train and test sets (90/10 split)\n",
        "\n",
        "# create bool mask to apply random uniform selection of df for training\n",
        "msk = np.random.rand(len(df)) < 0.9\n",
        "df_train = df[msk]\n",
        "df_test = df[~msk]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWYXNwfPgr8-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "0902f35e-3529-4567-f715-987b753d76cd"
      },
      "source": [
        "# include these preprocessing steps\n",
        "procs = [Categorify, Normalize]\n",
        "\n",
        "# set validation data range within training set\n",
        "val_pct = 0.1\n",
        "valid_idx = range(len(df_train) - round( val_pct*len(df_train) ), len(df_train))\n",
        "\n",
        "# define dependent (target), categorical, and continuous variables\n",
        "dep_var = 'mean_travel_time'\n",
        "cat_names = ['dow','sourceid', 'dstid']\n",
        "cont_names = ['distance', 'standard_deviation_travel_time', 'geometric_standard_deviation_travel_time']\n",
        "\n",
        "# create a databunch\n",
        "#data = TabularDataBunch.from_df(path, df, dep_var, valid_idx=valid_idx, procs=procs, cat_names=cat_names)\n",
        "\n",
        "# test tabular list\n",
        "test = TabularList.from_df(df_test, cat_names=cat_names, cont_names=cont_names, procs=procs)\n",
        "\n",
        "# train data bunch\n",
        "data = (TabularList.from_df(df_train, path=path, cat_names=cat_names, cont_names=cont_names, procs=procs)\n",
        "                        .split_by_idx(valid_idx)\n",
        "                        .label_from_df(cols=dep_var)\n",
        "                        .add_test(test) # remove this from model; apply test after export and reload\n",
        "                        .databunch(bs=1024))\n",
        "\n",
        "# show continuous var names (excluding target)\n",
        "cont_names = data.train_ds.cont_names\n",
        "print(data.train_ds.cont_names, '\\n')\n",
        "\n",
        "# preview a few rows of one data batch with 'procs' applied\n",
        "data.show_batch(rows=5)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['distance', 'standard_deviation_travel_time', 'geometric_standard_deviation_travel_time'] \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>dow</th>\n",
              "      <th>sourceid</th>\n",
              "      <th>dstid</th>\n",
              "      <th>distance</th>\n",
              "      <th>standard_deviation_travel_time</th>\n",
              "      <th>geometric_standard_deviation_travel_time</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>350</td>\n",
              "      <td>227</td>\n",
              "      <td>-0.4455</td>\n",
              "      <td>0.5871</td>\n",
              "      <td>0.1327</td>\n",
              "      <td>1103.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>655</td>\n",
              "      <td>656</td>\n",
              "      <td>-1.1335</td>\n",
              "      <td>-0.6290</td>\n",
              "      <td>5.5171</td>\n",
              "      <td>313.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>191</td>\n",
              "      <td>23</td>\n",
              "      <td>-0.2658</td>\n",
              "      <td>0.2228</td>\n",
              "      <td>0.0646</td>\n",
              "      <td>1028.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>366</td>\n",
              "      <td>306</td>\n",
              "      <td>-1.2177</td>\n",
              "      <td>-0.9031</td>\n",
              "      <td>1.4618</td>\n",
              "      <td>267.39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>671</td>\n",
              "      <td>651</td>\n",
              "      <td>-0.6247</td>\n",
              "      <td>-0.0466</td>\n",
              "      <td>0.1668</td>\n",
              "      <td>899.14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLgLpPi3rF85",
        "colab_type": "code",
        "outputId": "a6e8efe5-6e4d-4456-b952-a87a46a32e44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "# initialize learner\n",
        "learn = tabular_learner(data, layers=[200,100], metrics=mean_absolute_error, callback_fns=ShowGraph)\n",
        "\n",
        "# create plot to select appropriate learning rate\n",
        "learn.lr_find()\n",
        "learn.recorder.plot()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAEKCAYAAAC7c+rvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJkdtRX42WgT",
        "colab_type": "code",
        "outputId": "c331e18e-0f0d-4d49-cc53-d9e723d92987",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 766
        }
      },
      "source": [
        "# fit model using selected learning rate\n",
        "learn.fit_one_cycle(15, max_lr=2e-1)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>mean_absolute_error</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>25762.410156</td>\n",
              "      <td>16604.824219</td>\n",
              "      <td>96.942650</td>\n",
              "      <td>00:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>10863.067383</td>\n",
              "      <td>15751.506836</td>\n",
              "      <td>96.084465</td>\n",
              "      <td>00:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>11086.836914</td>\n",
              "      <td>20900.531250</td>\n",
              "      <td>115.305099</td>\n",
              "      <td>00:15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>10386.590820</td>\n",
              "      <td>8920.645508</td>\n",
              "      <td>69.483734</td>\n",
              "      <td>00:15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>10803.862305</td>\n",
              "      <td>9797.323242</td>\n",
              "      <td>75.316353</td>\n",
              "      <td>00:15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>9558.250977</td>\n",
              "      <td>10873.405273</td>\n",
              "      <td>80.334129</td>\n",
              "      <td>00:15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>8950.358398</td>\n",
              "      <td>10229.153320</td>\n",
              "      <td>75.757034</td>\n",
              "      <td>00:15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>8402.222656</td>\n",
              "      <td>8639.273438</td>\n",
              "      <td>68.353279</td>\n",
              "      <td>00:15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>7913.709961</td>\n",
              "      <td>489397.062500</td>\n",
              "      <td>81.166977</td>\n",
              "      <td>00:15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>7214.141602</td>\n",
              "      <td>6891.637207</td>\n",
              "      <td>60.724457</td>\n",
              "      <td>00:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>6468.828613</td>\n",
              "      <td>5229.614746</td>\n",
              "      <td>52.180141</td>\n",
              "      <td>00:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>5464.062988</td>\n",
              "      <td>4731.121582</td>\n",
              "      <td>49.423759</td>\n",
              "      <td>00:15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>4372.966309</td>\n",
              "      <td>4292.606445</td>\n",
              "      <td>47.790356</td>\n",
              "      <td>00:15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>3849.095215</td>\n",
              "      <td>3725.239258</td>\n",
              "      <td>43.225048</td>\n",
              "      <td>00:15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>3363.463379</td>\n",
              "      <td>3599.103760</td>\n",
              "      <td>42.065289</td>\n",
              "      <td>00:15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAD8CAYAAACyyUlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XuYXNV55/vvW5fuVqtbLaklIVAL\nJIwMuoCEEFgxsUMgBoFtRMZcJJyDxsOY59g4tuNxEnEy55BxzHnwTJ4h5oxNhhiNRR4jQWTHKD7C\nGowhJGfMRdi6clMDwmqBpNb92req9/yxV6lLrarurqpuVVf37/PQT+9699p7rY1KemvttWstc3dE\nRERKESt3A0REpPIpmYiISMmUTEREpGRKJiIiUjIlExERKZmSiYiIlEzJRERESqZkIiIiJVMyERGR\nkiXK3YCzJV7b4JdechGJmJW7KSIiFeO1117b5+4T+yo3YpJJomESq9c9zyWTx5S7KSIiFcPM3u9P\nuRF1m2vR3/xLuZsgIjIsjahkAvD2nqPlboKIyLAz4pLJ9Q+9WO4miIgMOyNmzEREpFCdnZ20tLTQ\n1tZW7qYMupqaGpqamkgmk0UdP6KSyR9fexH/zy+baetMUZOMl7s5IjLEtbS0UF9fz7Rp0zAbvk+C\nujv79++npaWF6dOnF3WOEXWba2J9NQC//u3BMrdERCpBW1sbjY2NwzqRAJgZjY2NJfXARlQymX/+\nOAA2txwuc0tEpFIM90SSUep1jphkYsDs88YwpibBi2+3lrs5IiLDyohJJhBl3o9d2Mj/emc/qbSX\nuzkiIr06dOgQ3//+9ws+7qabbuLQoUOD0KL8RlQyATi3oQaAn23+oMwtERHpXb5k0tXV1etx69at\nY+zYsYPVrJxGTDLJ3A/85g0XA/Bu6/FyNkdEpE/Lly/nnXfeYd68eVx55ZV84hOf4Oabb2bWrFkA\n3HLLLVxxxRXMnj2bRx999NRx06ZNY9++fezYsYOZM2fyxS9+kdmzZ3P99ddz8uTJQWnriHo0GGBM\nTZLzGmrYefBEuZsiIhXkP/3TNl7/4MiAnnPWeWO4/7Oz8+5/8MEH2bp1Kxs3buSFF17g05/+NFu3\nbj31+O6KFSsYP348J0+e5Morr+Rzn/scjY2Np51j+/btrFq1ir/7u7/j9ttv58c//jF/9Ed/NKDX\nAf3omZjZCjPba2Zbe8T/2MzeNLNtZvafs+L3mVmzmb1lZjdkxReFWLOZLc+KTzezl0P8STOrCvHq\n8Lo57J/WVx29mXVu9wSPTeNr2XlAyUREKstVV1112vdAHn74YebOncvChQvZuXMn27dvP+OY6dOn\nM2/ePACuuOIKduzYMSht60/P5IfAfwMezwTM7PeBxcBcd283s0khPgtYAswGzgN+YWYfDYd9D/gU\n0AK8amZr3f114DvAQ+6+2sz+FrgbeCT8PujuF5nZklDujnx1uHuqt4vIfurt/PG1/Mt2PdElIv3X\nWw/ibBk9evSp7RdeeIFf/OIX/OpXv6K2tpZrrrkm5/dEqqurT23H4/FBu83VZ8/E3V8EDvQIfwl4\n0N3bQ5m9Ib4YWO3u7e7+HtAMXBV+mt39XXfvAFYDiy0ayLgWWBOOXwncknWulWF7DXBdKJ+vjn47\nf3wte460c6Kj90EsEZFyqq+v5+jR3JPTHj58mHHjxlFbW8ubb77JSy+9dJZbd7piB+A/Cnwi3H76\nZzO7MsSnADuzyrWEWL54I3DI3bt6xE87V9h/OJTPd65+u3hyPQBv7dYMwiIydDU2NnL11VczZ84c\n/vRP//S0fYsWLaKrq4uZM2eyfPlyFi5cWKZWRoodgE8A44GFwJXAU2Z24YC1aoCY2T3APQDnn3/+\nqfiFE6Ku4s6DJ7k8fCteRGQoeuKJJ3LGq6ureeaZZ3Luy4yLTJgwga1bu4e7v/nNbw54+zKK7Zm0\nAD/xyCtAGpgA7AKmZpVrCrF88f3AWDNL9IiTfUzY3xDK5zvXGdz9UXdf4O4LJk7sXnVyUn30XZO9\nR4b/TKAiImdDscnkp8DvA4QB9ipgH7AWWBKexJoOzABeAV4FZoQnt6qIBtDXursDzwO3hvMuA54O\n22vDa8L+X4by+erotzGjElQlYrQebS/i0kVEpKc+b3OZ2SrgGmCCmbUA9wMrgBXhceEOYFn4h36b\nmT0FvA50AfdmnrIys68A64E4sMLdt4Uq/hxYbWbfBn4DPBbijwF/b2bNRA8ALAFw97x19JeZcc6Y\navaoZyIiMiD6TCbuvjTPrpzfenH3B4AHcsTXAetyxN8lx9NY7t4G3FZIHYWYVF/DXvVMREQGxIiZ\nTqWnSfXqmYiIDJQRnUw0ZiIiMjBGbDKZUFfNkbYu2joLGm4RERmy6urqAPjggw+49dZbc5a55ppr\n2LBhw4DXPXKTSVjC98DxjjK3RERkYJ133nmsWbOm74IDaMQmk/GjqwAlExEZupYvX873vve9U6//\n8i//km9/+9tcd911zJ8/n0svvZSnn376jON27NjBnDlzADh58iRLlixh5syZ/OEf/qGmoB9ojSGZ\n7FcyEZH+eGY57N4ysOecfCnc+GDe3XfccQdf//rXuffeewF46qmnWL9+PV/96lcZM2YM+/btY+HC\nhdx8881513B/5JFHqK2t5Y033mDz5s3Mnz9/YK8hGLHJpLtnokF4ERmaLr/8cvbu3csHH3xAa2sr\n48aNY/LkyfzJn/wJL774IrFYjF27drFnzx4mT56c8xwvvvgiX/3qVwG47LLLuOyyywalrSM2mTSO\njsZM9h9Tz0RE+qGXHsRguu2221izZg27d+/mjjvu4Ec/+hGtra289tprJJNJpk2blnPq+bNtxI6Z\n1NckiMdMYyYiMqTdcccdrF69mjVr1nDbbbdx+PBhJk2aRDKZ5Pnnn+f999/v9fhPfvKTpyaL3Lp1\nK5s3bx6Udo7YnkksZoyrrVIyEZEhbfbs2Rw9epQpU6Zw7rnn8vnPf57PfvazXHrppSxYsIBLLrmk\n1+O/9KUv8YUvfIGZM2cyc+ZMrrjiikFp54hNJhANwmsAXkSGui1bugf+J0yYwK9+9auc5Y4dOwbA\ntGnTTk09P2rUKFavXj3obRyxt7kgGoRXz0REpHQjO5nUKZmIiAyEEZ1MGkdXsf+YHg0Wkfyi1TWG\nv1Kvc0Qnk/GjqzjS1kVnKl3upojIEFRTU8P+/fuHfUJxd/bv309NTU3R5xjxA/AAB493MGlM8f8T\nRWR4ampqoqWlhdbW1nI3ZdDV1NTQ1NRU9PH9WWlxBfAZYK+7z+mx7z8Afw1MdPd9Fn2f/7vATcAJ\n4N+6+69D2WXAfwyHftvdV4b4FcAPgVFEi2d9zd3dzMYDTwLTgB3A7e5+sLc6CjU+fHHxwAklExE5\nUzKZZPr06eVuRkXoz22uHwKLegbNbCpwPfDbrPCNRGuyzwDuAR4JZccTLff7MaJVFe83s3HhmEeA\nL2Ydl6lrOfCcu88Anguv89ZRjFNTquhb8CIiJekzmbj7i0RrsPf0EPBnQPbNxMXA4x55CRhrZucC\nNwDPuvsBdz8IPAssCvvGuPtLYQ35x4Fbss61Mmyv7BHPVUfBGus02aOIyEAoagDezBYDu9x9U49d\nU4CdWa9bQqy3eEuOOMA57v5h2N4NnNNHHQXTNPQiIgOj4AF4M6sF/g+iW1xnRRhDKfhxCjO7h+hW\nGOeff/4Z+8fVVmGmnomISKmK6Zl8BJgObDKzHUAT8GszmwzsAqZmlW0Ksd7iTTniAHsyt6/C770h\nnu9cZ3D3R919gbsvmDhx4hn74zFj7KikpqEXESlRwcnE3be4+yR3n+bu04huM813993AWuAuiywE\nDodbVeuB681sXBh4vx5YH/YdMbOF4Smtu4DMsmFrgWVhe1mPeK46iqIpVUREStefR4NXAdcAE8ys\nBbjf3R/LU3wd0SO7zUSP7X4BwN0PmNlfAa+Gct9y98yg/pfpfjT4mfAD8CDwlJndDbwP3N5bHcVS\nMhERKV2fycTdl/axf1rWtgP35im3AliRI74BmJMjvh+4Lkc8bx3FaBiV5IND5V9YRkSkko3o6VQA\nxtQkOdLWWe5miIhUNCWTUUmOnFQyEREphZLJqCRH27tIp4f3RG4iIoNJyaQmgTsc6+gqd1NERCqW\nksmoJIBudYmIlEDJpCaTTNQzEREplpLJqOjp6MPqmYiIFE3JJNMz0ePBIiJFG/HJpEFjJiIiJRvx\nyaS7Z6IxExGRYo34ZFJXE42ZqGciIlK8EZ9M4jGjvjqhMRMRkRKM+GQCmSlVdJtLRKRYSiZAfY16\nJiIipVAyQZM9ioiUSsmEzDT0us0lIlKsPpOJma0ws71mtjUr9l/M7E0z22xm/2hmY7P23WdmzWb2\nlpndkBVfFGLNZrY8Kz7dzF4O8SfNrCrEq8Pr5rB/Wl91FKtBPRMRkZL0p2fyQ2BRj9izwBx3vwx4\nG7gPwMxmAUuA2eGY75tZ3MziwPeAG4FZwNJQFuA7wEPufhFwELg7xO8GDob4Q6Fc3joKvO7TjBml\nMRMRkVL0mUzc/UXgQI/Y/3T3zH2hl4CmsL0YWO3u7e7+HtE67VeFn2Z3f9fdO4DVwGIzM+BaYE04\nfiVwS9a5VobtNcB1oXy+Ooo2pibJMa1pIiJStIEYM/l3wDNhewqwM2tfS4jlizcCh7ISUyZ+2rnC\n/sOhfL5zFW3MqCTucLRd4yYiIsUoKZmY2V8AXcCPBqY5A8vM7jGzDWa2obW1NW+5MfoWvIhISYpO\nJmb2b4HPAJ9398z9oV3A1KxiTSGWL74fGGtmiR7x084V9jeE8vnOdQZ3f9TdF7j7gokTJ+a9llML\nZGncRESkKEUlEzNbBPwZcLO7n8jatRZYEp7Emg7MAF4BXgVmhCe3qogG0NeGJPQ8cGs4fhnwdNa5\nloXtW4FfhvL56iiaFsgSESlNoq8CZrYKuAaYYGYtwP1ET29VA89GY+K85O7/u7tvM7OngNeJbn/d\n6+6pcJ6vAOuBOLDC3beFKv4cWG1m3wZ+AzwW4o8Bf29mzUQPACwB6K2OYmmBLBGR0vSZTNx9aY7w\nYzlimfIPAA/kiK8D1uWIv0uOp7HcvQ24rZA6iqUFskRESqNvwJM1ZqKeiYhIUZRMgPrqBGZaIEtE\npFhKJkAsZtRVJ9QzEREpkpJJEE32qGQiIlIMJZNAC2SJiBRPySQYowWyRESKpmQS1NckOK65uURE\niqJkEtRVJzimZCIiUhQlk6CuJsExPRosIlIUJZOgrjrJUSUTEZGiKJkE9TUJOlJp2rtKmuZLRGRE\nUjIJ6qqjacp0q0tEpHBKJsGpZKJBeBGRgimZBPVhtUWNm4iIFE7JJKirUc9ERKRYSiZBfXU0Db3G\nTERECtdnMjGzFWa218y2ZsXGm9mzZrY9/B4X4mZmD5tZs5ltNrP5WccsC+W3m9myrPgVZrYlHPOw\nhaUbi6mjFOqZiIgUrz89kx8Ci3rElgPPufsM4LnwGuBGojXZZwD3AI9AlBiIlvv9GNGqivdnkkMo\n88Ws4xYVU0epMgPwR5VMREQK1mcycfcXidZgz7YYWBm2VwK3ZMUf98hLwFgzOxe4AXjW3Q+4+0Hg\nWWBR2DfG3V9ydwce73GuQuooSWYAXre5REQKV+yYyTnu/mHY3g2cE7anADuzyrWEWG/xlhzxYuoo\nSXUiRiJmHGvXzMEiIoUqeQA+9Ch8ANoy4HWY2T1mtsHMNrS2tvZVlrqahB4NFhEpQrHJZE/m1lL4\nvTfEdwFTs8o1hVhv8aYc8WLqOIO7P+ruC9x9wcSJE/u8qLpqTfYoIlKMYpPJWiDzRNYy4Oms+F3h\niauFwOFwq2o9cL2ZjQsD79cD68O+I2a2MDzFdVePcxVSR8nqqhMagBcRKUKirwJmtgq4BphgZi1E\nT2U9CDxlZncD7wO3h+LrgJuAZuAE8AUAdz9gZn8FvBrKfcvdM4P6XyZ6YmwU8Ez4odA6BkK9pqEX\nESlKn8nE3Zfm2XVdjrIO3JvnPCuAFTniG4A5OeL7C62jVPU1SVqPtg/GqUVEhjV9Az6LVlsUESmO\nkkkWPc0lIlIcJZMs9dUJfc9ERKQISiZZ6qoTtHWm6Uyly90UEZGKomSSJTPZ43GNm4iIFETJJMup\nyR41biIiUhAlkyxabVFEpDhKJlnqMgtk6TaXiEhBlEyydC+QpSe6REQKoWSSRWMmIiLFUTLJMkZL\n94qIFEXJJEudVlsUESmKkkmWUck4MVPPRESkUEomWcwsWtNEPRMRkYIomfRQX5NUz0REpEBKJj1o\n6V4RkcKVlEzM7E/MbJuZbTWzVWZWY2bTzexlM2s2syfNrCqUrQ6vm8P+aVnnuS/E3zKzG7Lii0Ks\n2cyWZ8Vz1jEQ6moSHNX3TEREClJ0MjGzKcBXgQXuPgeIA0uA7wAPuftFwEHg7nDI3cDBEH8olMPM\nZoXjZgOLgO+bWdzM4sD3gBuBWcDSUJZe6iiZeiYiIoUr9TZXAhhlZgmgFvgQuBZYE/avBG4J24vD\na8L+68zMQny1u7e7+3tEa7tfFX6a3f1dd+8AVgOLwzH56ihZ1DNRMhERKUTRycTddwF/DfyWKIkc\nBl4DDrl75l/jFmBK2J4C7AzHdoXyjdnxHsfkizf2UkfJ6tUzEREpWCm3ucYR9SqmA+cBo4luUw0Z\nZnaPmW0wsw2tra39Oqa+RuvAi4gUqpTbXH8AvOfure7eCfwEuBoYG257ATQBu8L2LmAqQNjfAOzP\njvc4Jl98fy91nMbdH3X3Be6+YOLEif26qLrqJCc6UqTS3q/yIiJSWjL5LbDQzGrDOMZ1wOvA88Ct\nocwy4OmwvTa8Juz/pbt7iC8JT3tNB2YArwCvAjPCk1tVRIP0a8Mx+eooWZ3m5xIRKVgpYyYvEw2C\n/xrYEs71KPDnwDfMrJlofOOxcMhjQGOIfwNYHs6zDXiKKBH9HLjX3VNhTOQrwHrgDeCpUJZe6ihZ\nfbWSiYhIoRJ9F8nP3e8H7u8RfpfoSayeZduA2/Kc5wHggRzxdcC6HPGcdQwETfYoIlI4fQO+h7pq\nLZAlIlIoJZMe6rQOvIhIwZRMeqjXaosiIgVTMulBT3OJiBROyaSHU2Mm6pmIiPSbkkkPo6sSmKH5\nuURECqBk0kMsZtRVaX4uEZFCKJnkUFeT0KPBIiIFUDLJoa5akz2KiBRCySSHupqEHg0WESmAkkkO\n6pmIiBRGySSH+hoNwIuIFELJJIe6at3mEhEphJJJDnXVSd3mEhEpgJJJDnVh6d60VlsUEekXJZMc\nMpM9Hu9Q70REpD9KSiZmNtbM1pjZm2b2hpn9jpmNN7NnzWx7+D0ulDUze9jMms1ss5nNzzrPslB+\nu5kty4pfYWZbwjEPh+WByVfHQNFkjyIihSm1Z/Jd4Ofufgkwl2h53eXAc+4+A3guvAa4kWh99xnA\nPcAjECUGotUaP0a0euL9WcnhEeCLWcctCvF8dQyIeq22KCJSkKKTiZk1AJ8krL/u7h3ufghYDKwM\nxVYCt4TtxcDjHnkJGGtm5wI3AM+6+wF3Pwg8CywK+8a4+0vu7sDjPc6Vq44BkZk5WJM9ioj0Tyk9\nk+lAK/A/zOw3ZvYDMxsNnOPuH4Yyu4FzwvYUYGfW8S0h1lu8JUecXuoYEOqZiIgUppRkkgDmA4+4\n++XAcXrcbgo9ikF9JKq3OszsHjPbYGYbWltb+33OuuokoDETEZH+KiWZtAAt7v5yeL2GKLnsCbeo\nCL/3hv27gKlZxzeFWG/xphxxeqnjNO7+qLsvcPcFEydO7PeF1alnIiJSkKKTibvvBnaa2cUhdB3w\nOrAWyDyRtQx4OmyvBe4KT3UtBA6HW1XrgevNbFwYeL8eWB/2HTGzheEprrt6nCtXHQNCYyYiIoVJ\nlHj8HwM/MrMq4F3gC0QJ6ikzuxt4H7g9lF0H3AQ0AydCWdz9gJn9FfBqKPctdz8Qtr8M/BAYBTwT\nfgAezFPHgDiVTNq0pomISH+UlEzcfSOwIMeu63KUdeDePOdZAazIEd8AzMkR35+rjoESjxm1VXHd\n5hIR6Sd9Az4PTUMvItJ/SiZ51NUkNGYiItJPSiZ51FdrTRMRkf5SMsmjvkbT0IuI9JeSSR516pmI\niPSbkkkemTVNRESkb0omeURL9+p7JiIi/aFkkkd96JlEX48RGebSaUinyt0KqWBKJnnUVSdIO5zs\n1F8wGQH+6Y9hxSLQhycpkpJJHpnJHo9qEF6Gu5MHYfM/QMsrsHtzuVsjFUrJJI/u+bmUTGSY2/oT\nSLWDxWDjqnK3RiqUkkke9VoHXkaKTatg0iy45NOw5R8gpQdPpHBKJnmcWiBLPRMZzvZth5ZXYe5S\nmHsnnNgHzb8od6ukAimZ5JG5zXWsXZ/SZBjbtCq6vXXZ7TDjU1A7ATY+Ue5WSQVSMsmjXgPwMtyl\n07DpSfjIdVA/GeJJuPQ2ePvncOJA38eLZFEyyUNjJjLs7XgRjrTAvKXdsXlLIdUBW39cvnZJRSo5\nmZhZ3Mx+Y2Y/C6+nm9nLZtZsZk+GVRgxs+rwujnsn5Z1jvtC/C0zuyErvijEms1seVY8Zx0DaXS1\n1oGXYW7jKqhugIs/3R2bfBlMmh3d/hIpwED0TL4GvJH1+jvAQ+5+EXAQuDvE7wYOhvhDoRxmNgtY\nAswGFgHfDwkqDnwPuBGYBSwNZXurY8Ak4zFqkjH1TGR4aj8Kb6yFOf8GkjXdcTOYuwR2vQatb5ev\nfVJxSkomZtYEfBr4QXhtwLXAmlBkJXBL2F4cXhP2XxfKLwZWu3u7u79HtEb8VeGn2d3fdfcOYDWw\nuI86BlRddVILZMnw9PrT0HkC5t155r7Lbo8G5dU7kQKU2jP5G+DPgHR43QgccvfMv8AtwJSwPQXY\nCRD2Hw7lT8V7HJMv3lsdA6q+JqEBeBmeNq6C8R+BpivP3Fc/ORqU3/yk5uuSfis6mZjZZ4C97v7a\nALZnQJnZPWa2wcw2tLa2Fnx8tKaJHg2WYebgDnj/X6PBdrPcZeYthSO74L0Xz2rTpHKV0jO5GrjZ\nzHYQ3YK6FvguMNbMEqFME7ArbO8CpgKE/Q3A/ux4j2Pyxff3Usdp3P1Rd1/g7gsmTpxY8AXWVWtN\nExmGNj0JGFy2JH+Zi2+KBuc3rT5rzZLKVnQycff73L3J3acRDaD/0t0/DzwP3BqKLQOeDttrw2vC\n/l96NL/7WmBJeNprOjADeAV4FZgRntyqCnWsDcfkq2NA1ek2lww37tFYyPRPwNip+cslR8HsW6JB\n+vajZ699UrEG43smfw58w8yaicY3Hgvxx4DGEP8GsBzA3bcBTwGvAz8H7nX3VBgT+QqwnuhpsadC\n2d7qGFD16pnIcPPbl+Dge9HUKX2Zd2c0SP/62sFvl1S8RN9F+ubuLwAvhO13iZ7E6lmmDbgtz/EP\nAA/kiK8D1uWI56xjoNVr6V4Zbjb+CJKjYeZn+y479WMw/sKoJ3P55we/bVLR9A34XtTVJDjWptUW\nZZjoOAHbfhrdvqqu67u8WTQB5I5/gYPvD377pKIpmfSirjpJV9pp60z3XVhkqHvz/4WOo1GC6K/L\n7oh+b35qcNokw4aSSS/GjIruAh4+qceDZRjY9AQ0nA8XXN3/Y8ZdABf8bnSrSz106YWSSS8aR0dT\nfh043lHmloiU6MgH8O4L0VQpsQL/2s9bCgfegZ2vDErTZHhQMunFuNoomRw8oWQiFW7zk+DpKJkU\natZiSNZGPRuRPJRMejFePRMZDtyj6VOmLoTGjxR+fHV99PTX1n+EzpMD3z4ZFpRMejFutHomMgzs\n+jXse+v0dUsKNXcJtB+Gt54ZuHbJsKJk0ouxo6J14NUzkYq26QlI1MDsPyz+HNN/D+rP00zCkpeS\nSS8S8RgNo5IcVDKRStXVDlvWwCWfgZqG4s8Ti8PcO6D5OTi6Z+DaJ8OGkkkfxo+u4sAJPRosFert\nn0PbodJucWXMvRM8BVv0nRM5k5JJH8bVqmciFWzjKqg/Fy78/dLPNfGjMOWK6Jz6zon0oGTSh/Gj\nqzRmIpXpWCs0PxutnBiLD8w55y6Fvdtg95aBOZ8MG0omfRhXW6WnuaQybfkHSHf1b4bg/przOYgl\nNRAvZ1Ay6UOmZ6LJHqXibHwCzrscJl0ycOesHQ8XL4rm6kppLFG6KZn0YdzoKtq70hzv0FrYUkF2\nb4E9Wwa2V5Ix9044sQ+afzHw55aKpWTSh0n11QDsPdJW5paIFGDjquh21KW39l22UDM+BbWNUc9H\nJCg6mZjZVDN73sxeN7NtZva1EB9vZs+a2fbwe1yIm5k9bGbNZrbZzOZnnWtZKL/dzJZlxa8wsy3h\nmIfNzHqrYzBMHlMDwG4lE6kUqc7o8d2LF0W3pQZaPAmX3hY9dnziwMCfXypSKT2TLuA/uPssYCFw\nr5nNIlqO9zl3nwE8F14D3Ei0vvsM4B7gEYgSA3A/8DGi1RPvz0oOjwBfzDpuUYjnq2PAndMQJZM9\nSiZSKZqfg+Otg3OLK2PuUkh1wLafDF4dUlGKTibu/qG7/zpsHyVap30KsBhYGYqtBG4J24uBxz3y\nEjDWzM4FbgCedfcD7n4QeBZYFPaNcfeXPBr9frzHuXLVMeBO9UwOtw9WFSIDa9MTUDshuh01WM6d\nC5NmRbfTRBigMRMzmwZcDrwMnOPuH4Zdu4FzwvYUYGfWYS0h1lu8JUecXuoYcKOrE9RXJ9Qzkcpw\n4kA0GeOlt0W3owZLZknfXRtg3/bBq0cqRsnJxMzqgB8DX3f3I9n7Qo9iUJ+p7a0OM7vHzDaY2YbW\n1tai6zinoYbdh5VMpAJs/XF0+2kgpk/py2W3g8U0EC9AicnEzJJEieRH7p65ebon3KIi/N4b4ruA\nqVmHN4VYb/GmHPHe6jiNuz/q7gvcfcHEiROLu0iiW10agJeKsGkVTJoNky8b/LrqJ8NHro0W3kqn\nB78+GdJKeZrLgMeAN9z9v2btWgtknshaBjydFb8rPNW1EDgcblWtB643s3Fh4P16YH3Yd8TMFoa6\n7upxrlx1DIrJDTV8eFiLAskQ1/o27HoN5t0Z3YY6G+YuhSO7YMeLZ6c+GbJK6ZlcDfxvwLVmtjH8\n3AQ8CHzKzLYDfxBeA6wD3gVeoxlfAAANdElEQVSagb8Dvgzg7geAvwJeDT/fCjFCmR+EY94BMivz\n5KtjUFwwvpY9R9o5qS8uylC26QmweHT76Wy55NNQ3aCBeCFR7IHu/q9Avo8/1+Uo78C9ec61AliR\nI74BmJMjvj9XHYNl2oTRAOzYf5yZ5445W9WK9F86BZuehIv+AOomnb16k6Ng9i3RPGDtfx0t8Ssj\nkr4B3w/TM8lk3/Eyt0Qkj/f+GY5+cHYG3nuadyd0noA3/uns1y1DhpJJP1zQWAvAe/uVTGSI2rgq\nWknxozee/bqnfgzGTddTXSOckkk/1NckmVBXpZ6JDE1tR6JewZzPQbLm7Nef+c7Jjn+BQ789+/XL\nkKBk0k8XTarjrT3Hyt0MkTO9/lPoOjm406f0Ze6S6PemJ8vXBikrJZN+unRKA298eITOlJ6nlyFm\n4ypovAiaFpSvDeMugAt+N/qei9b+GZGUTPppzpQGOrrSNO9V70SGkAPvwW//19n9bkk+c5fAgXeg\n5dXytkPKQsmkn+ZMaQBgy67DZW6JSJZNqwGDy5aUuyUwazEkRmkgfoRSMumn6Y2jqa9J8NqOg+Vu\nikgknY5uK134e9Awpe/yg61mDMz8bDQtfaemHxpplEz6KRYzPv6RRv61eZ/Wg5eh4be/gkPvl3fg\nvad5S6HtMLy1rtwtkbNMyaQAn5gxkV2HTvKeHhGWoWDjE1BVBzM/U+6WdJv+e1B/XtRjkhFFyaQA\nv/fRaObh9dv2lLklMuJ1HI8eCZ51C1SNLndrusXC3GDNz8FR/T0ZSZRMCjB1fC3zzx/LT37doltd\nUl5v/Aw6jpVn+pS+zLsTPBXN1yUjhpJJgW69Yirb9x7jVQ3ESzltegLGXgDnf7zcLTnTxIvhvPm6\n1TXCKJkU6JbLz2NifTX/Zf2bpNPqnUgZHG6Bd/85msIkNkT/Cs+7E/ZshQ83l7slcpYM0Xfi0FVb\nleCb13+UV3ccZMX/9165myMj0eYnAe+ewmQomvM5iCXVOxlBlEyKcPuCqXxq1jn83+ve4KkNO8vd\nHBlJ3KPpU87/OIyfXu7W5Fc7Hj56QzRukuosd2vkLCh6cayhwMwWAd8F4sAP3H1QV1zMqpeHl1zO\nF1e+zH9c8xovvN7Cv//kR5jXNJ5YLBZNazGQU1u4Q6oDutqjn1R77u3e9qU6oKst2rZYNF35qLFQ\nMxZGjTt9u6YheipHhp6WDbB/O1z91XK3pG/z7oQ3fxY92XXxonK3RgZZxSYTM4sD3wM+BbQAr5rZ\nWnd//WzUP6oqzg//wEnsWhYtRvxu7nJODDcjWpTSou2er4liTvc2FsPSncRSHcTSHQPSZidGKl6F\neZp4H+fsTNSRqm4gVT2WVHUDXVVj6Eo20JXZrmqgs2oMncmxtCXq6UiOIV1Vj5sRA+LmmENXKkVH\nVxdxg0QcquJGVcxo70zR1tlFPOYkY0YyBu5OVypNVypFzJyEQTodxdzT1CSMmoRRnTASMejoTBHD\niRmkUymScUin0xw41kZHV4rqOFQlYiRjEDeIkSaVdjydIhEzahJQlYiTjBtmsVP/71NpxzEs82dl\n0bYR/bmk3OnogpSncYy4xYjFjHg8RiwWI2aGxeI4RgojFotjsRhmccj8thidbiTiMbCorFucNEYa\nI+VGdTJJVVWCWCwOZsRiCeK/+XtiiVEwa3HeZU5P+3NMpelKOWZQFY/aedZc9CmobYweFlAyGfYq\nNpkAVwHN7v4ugJmtBhYDZyWZACTGXwDX/p+0daZ4t/UoO/YdZ/+xNg6daA+D845F6YTuVOFZP92v\nM2XIiqWI00GSdpK0e+LUdgdJOjxxarudJB2epIMoFsUTtHsVHXQfl6K7t1FNB2M4zlg7TgPHaLDj\nNHA8+m3Haeg6TkN7JraPBt6nwY7TyDGqrets/S8uyrRyN2CQ/TT1cb7+l/9KzCAes+jHot+xWJQM\nU2mnK+10dJ0+y3WUUMAwYgYxMwi/M68TcSMZj+6At3WmAQ/JNOTWcKyF3reF48KporJh+96uj3Pz\n6z/jvW/Nx81IEyNNDLfwG6PLDbdY+OAV/XDatpEiFiVZosSbxkhbHCPUFRJ+9IEAIJa1qHjU9swH\nt+ztqEyOeObCTsW7z2lEH8y6Dz/zmDNeh3osU1/48GjZbcjUF15nf9A8rZ7wwcYz8VMfQLtfZ26M\ndB/X/WeTtePUn2lm+1RzwkYhHz0qOZlMAbIHLFqAj53VFjQ0wSe/SQ0wK/xA9An7ZGeKwyc7OdrW\nRdqddBocxz26a+U4aefUH6Y7UTmPjk+H15l41t+L0/4yuztO96zfjhP+I2ZGMh59+k3Eon8kEjEj\nlYaudJp0GlLuNIxKEjfjZGeKEx1dp/5BaetMcbIjzUmcNoy9BuZOLN1GouMwifYjVHUepjp1lGTH\nEWIdR0N7utMisRhViTjpNHRhdKaclEMyHieZiD6Jd6WdVDr6y5CIx4jH46QdUg6xWIx4LIZZjI4U\ntKfStKegM+VUJRPR/x8MiyXoTKcxizN2dBWjqpK0dzntKacj5VGvLJwvFovRmYK2VJq2znT4B9cx\njz4ARP+oRn9Q7mCeDv9fHXcnEYv+UU7ELcQyPZ7od9rTkE6Hf2QdUl3goY50Coj2J2Lg6RTmUX8k\n+uc0jeHEcVKpLlKpVHSsp6N2uHNg0g18LXlO9GfoofcWEkja/bTkMro6QVUiRtqd9s407V3p8P7K\nvLei9xdEvzOJqCOVBofqZPzU+xN6vI/DMWRtZ+Ietn/TuYQL9h0hke4g5mkgTSxcbwIn5mlqzTHv\niP7fewo8ShexdHf5WHcaCh++UsQ8jcOpd1vmL8Gp16e/E0/b3/2P5Okf4rr/mvU4ljOPjfafGY9l\nnWckqeRk0iczuwe4J7xsN7Ot5WzPAJsA7Ct3IwbYcLumQbqeBwb+lP1T1PV8exAaMoD0nuvbBf0p\nVMnJZBcwNet1U4id4u6PAo8CmNkGdy/j6kEDa7hdDwy/a9L1DH3D7ZrKeT2V/Gjwq8AMM5tuZlXA\nEmBtmdskIjIiVWzPxN27zOwrwHqiR4NXuPu2MjdLRGREqthkAuDu64D+Lpzw6GC2pQyG2/XA8Lsm\nXc/QN9yuqWzXY5r9VkRESlXJYyYiIjJEjIhkYmaLzOwtM2s2s+Xlbk8+ZrbCzPZmP8JsZuPN7Fkz\n2x5+jwtxM7OHwzVtNrP5WccsC+W3m9myclxLaMdUM3vezF43s21m9rVKviYzqzGzV8xsU7ie/xTi\n083s5dDuJ8MDIZhZdXjdHPZPyzrXfSH+lpndUI7ryWpL3Mx+Y2Y/C68r/Xp2mNkWM9toZhtCrCLf\nc6EdY81sjZm9aWZvmNnvDMnr8fBFrOH6QzQ4/w5wIVAFbAJmlbtdedr6SWA+sDUr9p+B5WF7OfCd\nsH0T8AzRd6oWAi+H+HiiyV3GA+PC9rgyXc+5wPywXQ+8TfTdzoq8ptCuurCdBF4O7XwKWBLifwt8\nKWx/GfjbsL0EeDJszwrvw2pgenh/xsv4vvsG8ATws/C60q9nBzChR6wi33OhLSuBfx+2q4CxQ/F6\nyvKHfZb/IH4HWJ/1+j7gvnK3q5f2TuP0ZPIWcG7YPhd4K2z/d2Bpz3LAUuC/Z8VPK1fma3uaaC61\nir8moBb4NdGsC/uARM/3G9GThr8TthOhnPV8D2aXK8N1NAHPAdcCPwvtq9jrCfXv4MxkUpHvOaAB\neI8wvj2Ur2ck3ObKNe3KlDK1pRjnuPuHYXs3cE7YznddQ/J6wy2Ry4k+zVfsNYVbQhuBvcCzRJ/C\nD7l7ZsKy7LadanfYfxhoZAhdD/A3wJ8BmUm8Gqns64FojpP/aWavWTQLBlTue2460Ar8j3Ar8gdm\nNpoheD0jIZkMGx59pKi4x+/MrA74MfB1dz+Sva/SrsndU+4+j+gT/VXAJWVuUtHM7DPAXnd/rdxt\nGWC/6+7zgRuBe83sk9k7K+w9lyC69f2Iu18OHCe6rXXKULmekZBM+px2ZYjbY2bnAoTfe0M833UN\nqes1syRRIvmRu/8khCv6mgDc/RDwPNFtoLFmlvnOVnbbTrU77G8A9jN0rudq4GYz2wGsJrrV9V0q\n93oAcPdd4fde4B+Jkn6lvudagBZ3fzm8XkOUXIbc9YyEZFLp066sBTJPXiwjGnfIxO8KT28sBA6H\nbu964HozGxee8Lg+xM46MzPgMeANd/+vWbsq8prMbKKZjQ3bo4jGf94gSiq3hmI9rydznbcCvwyf\nItcCS8LTUdOBGcArZ+cqurn7fe7e5O7TiP5e/NLdP0+FXg+AmY02s/rMNtF7ZSsV+p5z993ATjO7\nOISuI1pmY+hdz9keUCrHD9ETDm8T3d/+i3K3p5d2rgI+BDqJPpHcTXRP+jlgO/ALYHwoa0SLg70D\nbAEWZJ3n3wHN4ecLZbye3yXqfm8GNoafmyr1moDLgN+E69kK/F8hfiHRP57NwD8A1SFeE143h/0X\nZp3rL8J1vgXcOATee9fQ/TRXxV5PaPum8LMt8/e9Ut9zoR3zgA3hffdToqexhtz16BvwIiJSspFw\nm0tERAaZkomIiJRMyUREREqmZCIiIiVTMhERkZIpmYiISMmUTEREpGRKJiIiUrL/H5HTxIkipYjI\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ub7B3Z1o6YHy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# export the model\n",
        "if False:\n",
        "  learn.export('model_epoch_15_mae_42.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8S5VaFYIe_C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reload model for use with test data\n",
        "learn = load_learner(path, 'model_epoch_15_mae_42.pkl', test=df_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjvYeNRFJXzg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "6d1be077-a8d3-4a11-f0e5-eced98dc262e"
      },
      "source": [
        "# use model for predictions on test data\n",
        "y_test = df_test['mean_travel_time']\n",
        "X_test = df_test.drop('mean_travel_time', axis=1)\n",
        "\n",
        "# predict one item\n",
        "row = 5\n",
        "pred_val = learn.predict(X_test.iloc[row])[0].data[0]\n",
        "\n",
        "print('Features:\\n')\n",
        "print(X_test.iloc[5], '\\n')\n",
        "print('mean_travel_time prediction: {}'.format(round(pred_val.astype('float'),2)))\n",
        "print('mean_travel_time target:     {}'.format(y_test.iloc[row]))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features:\n",
            "\n",
            "sourceid                                    666.00000\n",
            "dstid                                        89.00000\n",
            "dow                                           4.00000\n",
            "standard_deviation_travel_time              770.84000\n",
            "geometric_standard_deviation_travel_time      1.44000\n",
            "distance                                     21.80136\n",
            "Name: 58, dtype: float64 \n",
            "\n",
            "mean_travel_time prediction: 1691.43\n",
            "mean_travel_time target:     1639.29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_NHe4nyDcF3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8f2b8d8d-3daf-470a-8335-e6241ec4bb6a"
      },
      "source": [
        "# make predictions for test set\n",
        "\n",
        "# create test tabular list\n",
        "tabList = TabularList.from_df(df_test, cat_names=cat_names, cont_names=cont_names, procs=procs)\n",
        "\n",
        "# reload model for use with tabList test set and get predictions\n",
        "learn = load_learner(path, 'model_epoch_15_mae_42.pkl', test=tabList)\n",
        "preds, _ = learn.get_preds(ds_type=DatasetType.Test)\n",
        "\n",
        "# calculate mae for test set\n",
        "preds_np = preds.numpy().ravel()\n",
        "targets = y_test.values.astype('float32')\n",
        "mae_nn = np.mean(abs(preds_np - targets)).astype('float')\n",
        "print('Mean Absolute Error using fastai neural net: {}'.format(round(mae_nn, 2)))"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Absolute Error using fastai neural net: 37.98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9qgA_ikm2fQ",
        "colab_type": "text"
      },
      "source": [
        "#### Keras sequential model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrOGu4R5uEGU",
        "colab_type": "code",
        "outputId": "33f90d58-97ff-4e8e-fa7b-42a96ae8f4ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# split training set into training and validation (reserve test set)\n",
        "xTrain_partial, x_val, yTrain_partial, y_val = train_test_split(xTrain, yTrain, test_size=0.2, random_state=42)\n",
        "\n",
        "# build sequential model\n",
        "model = Sequential()\n",
        "model.add(Dense(500, input_shape=(xTrain_partial.shape[1],), kernel_initializer='normal', activation='relu'))\n",
        "model.add(Dense(200, kernel_initializer='normal', activation='relu'))\n",
        "model.add(Dense(100, kernel_initializer='normal', activation='relu'))\n",
        "model.add(Dense(1, kernel_initializer='normal'))\n",
        "\n",
        "# compile model\n",
        "model.compile(loss='mean_absolute_error', optimizer=Adadelta())\n",
        "\n",
        "# add early stopping callback\n",
        "useEarlyStopping = True\n",
        "if useEarlyStopping:\n",
        "  callbacks = [EarlyStopping(monitor='val_loss', patience=20, min_delta=0.0001)]\n",
        "else:\n",
        "  callbacks=None\n",
        "\n",
        "# fit the model\n",
        "history = model.fit(xTrain_partial,\n",
        "                    yTrain_partial,\n",
        "                    epochs=100,\n",
        "                    verbose=1,\n",
        "                    batch_size=1024,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    callbacks=callbacks)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 345596 samples, validate on 86399 samples\n",
            "Epoch 1/100\n",
            "345596/345596 [==============================] - 3s 9us/step - loss: 534.3381 - val_loss: 611.0154\n",
            "Epoch 2/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 382.4815 - val_loss: 194.7999\n",
            "Epoch 3/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 292.2486 - val_loss: 367.3594\n",
            "Epoch 4/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 278.2095 - val_loss: 276.5358\n",
            "Epoch 5/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 264.7289 - val_loss: 296.5596\n",
            "Epoch 6/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 254.3581 - val_loss: 254.9961\n",
            "Epoch 7/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 244.2438 - val_loss: 273.8572\n",
            "Epoch 8/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 236.6796 - val_loss: 250.3918\n",
            "Epoch 9/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 229.3896 - val_loss: 259.4574\n",
            "Epoch 10/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 224.8086 - val_loss: 244.3622\n",
            "Epoch 11/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 217.7555 - val_loss: 223.4608\n",
            "Epoch 12/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 212.7550 - val_loss: 223.4700\n",
            "Epoch 13/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 208.2055 - val_loss: 225.9318\n",
            "Epoch 14/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 203.3762 - val_loss: 215.8109\n",
            "Epoch 15/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 200.3472 - val_loss: 204.8312\n",
            "Epoch 16/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 195.3334 - val_loss: 222.1708\n",
            "Epoch 17/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 192.9079 - val_loss: 193.7816\n",
            "Epoch 18/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 190.4815 - val_loss: 203.8168\n",
            "Epoch 19/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 187.9772 - val_loss: 192.5383\n",
            "Epoch 20/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 186.6199 - val_loss: 176.4679\n",
            "Epoch 21/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 183.1123 - val_loss: 192.6123\n",
            "Epoch 22/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 181.5504 - val_loss: 197.0362\n",
            "Epoch 23/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 178.8032 - val_loss: 177.8658\n",
            "Epoch 24/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 177.4577 - val_loss: 173.1867\n",
            "Epoch 25/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 175.4679 - val_loss: 175.9274\n",
            "Epoch 26/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 173.5258 - val_loss: 170.4525\n",
            "Epoch 27/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 171.6186 - val_loss: 174.4586\n",
            "Epoch 28/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 169.6045 - val_loss: 181.2475\n",
            "Epoch 29/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 168.3696 - val_loss: 187.7623\n",
            "Epoch 30/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 167.3244 - val_loss: 165.7475\n",
            "Epoch 31/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 164.8647 - val_loss: 164.1480\n",
            "Epoch 32/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 163.2642 - val_loss: 159.4374\n",
            "Epoch 33/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 162.1995 - val_loss: 175.8724\n",
            "Epoch 34/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 160.4954 - val_loss: 159.8286\n",
            "Epoch 35/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 158.5758 - val_loss: 162.7983\n",
            "Epoch 36/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 157.3354 - val_loss: 166.4086\n",
            "Epoch 37/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 155.5894 - val_loss: 143.0940\n",
            "Epoch 38/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 155.2800 - val_loss: 175.5921\n",
            "Epoch 39/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 153.1530 - val_loss: 174.7383\n",
            "Epoch 40/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 151.5799 - val_loss: 164.1986\n",
            "Epoch 41/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 150.3924 - val_loss: 157.2940\n",
            "Epoch 42/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 149.8417 - val_loss: 160.8924\n",
            "Epoch 43/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 148.1803 - val_loss: 157.1512\n",
            "Epoch 44/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 147.8665 - val_loss: 169.9220\n",
            "Epoch 45/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 145.0197 - val_loss: 159.0281\n",
            "Epoch 46/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 144.9201 - val_loss: 143.5390\n",
            "Epoch 47/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 143.5505 - val_loss: 161.1764\n",
            "Epoch 48/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 141.6935 - val_loss: 150.3841\n",
            "Epoch 49/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 140.0241 - val_loss: 144.2473\n",
            "Epoch 50/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 138.6948 - val_loss: 138.4675\n",
            "Epoch 51/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 137.6540 - val_loss: 146.5117\n",
            "Epoch 52/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 137.0745 - val_loss: 145.2376\n",
            "Epoch 53/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 135.2761 - val_loss: 147.9293\n",
            "Epoch 54/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 133.8898 - val_loss: 136.4222\n",
            "Epoch 55/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 132.9768 - val_loss: 147.8325\n",
            "Epoch 56/100\n",
            "345596/345596 [==============================] - 3s 9us/step - loss: 132.0109 - val_loss: 116.3681\n",
            "Epoch 57/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 129.8074 - val_loss: 135.6605\n",
            "Epoch 58/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 128.0232 - val_loss: 132.6288\n",
            "Epoch 59/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 127.6620 - val_loss: 133.9947\n",
            "Epoch 60/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 125.5585 - val_loss: 120.8655\n",
            "Epoch 61/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 124.0892 - val_loss: 128.2850\n",
            "Epoch 62/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 122.2024 - val_loss: 116.2967\n",
            "Epoch 63/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 120.9050 - val_loss: 126.5784\n",
            "Epoch 64/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 119.3059 - val_loss: 124.5084\n",
            "Epoch 65/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 117.8984 - val_loss: 110.1764\n",
            "Epoch 66/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 117.0035 - val_loss: 112.5222\n",
            "Epoch 67/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 115.6160 - val_loss: 116.8636\n",
            "Epoch 68/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 113.8534 - val_loss: 122.5026\n",
            "Epoch 69/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 112.7253 - val_loss: 101.3291\n",
            "Epoch 70/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 110.7429 - val_loss: 114.4821\n",
            "Epoch 71/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 109.1912 - val_loss: 115.0982\n",
            "Epoch 72/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 107.6939 - val_loss: 112.9525\n",
            "Epoch 73/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 106.1795 - val_loss: 100.7542\n",
            "Epoch 74/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 104.8544 - val_loss: 104.6253\n",
            "Epoch 75/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 103.6330 - val_loss: 93.3692\n",
            "Epoch 76/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 101.4790 - val_loss: 114.8027\n",
            "Epoch 77/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 99.7638 - val_loss: 115.4169\n",
            "Epoch 78/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 98.3920 - val_loss: 97.4909\n",
            "Epoch 79/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 96.1995 - val_loss: 100.7164\n",
            "Epoch 80/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 93.9566 - val_loss: 97.6433\n",
            "Epoch 81/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 91.6782 - val_loss: 92.4517\n",
            "Epoch 82/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 88.0029 - val_loss: 87.3614\n",
            "Epoch 83/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 87.3345 - val_loss: 88.9243\n",
            "Epoch 84/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 86.8820 - val_loss: 87.1155\n",
            "Epoch 85/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 86.5892 - val_loss: 87.0775\n",
            "Epoch 86/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 86.3859 - val_loss: 87.3712\n",
            "Epoch 87/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 86.2616 - val_loss: 87.7381\n",
            "Epoch 88/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 86.1346 - val_loss: 87.8039\n",
            "Epoch 89/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 85.8867 - val_loss: 88.7138\n",
            "Epoch 90/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 85.7751 - val_loss: 88.0958\n",
            "Epoch 91/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 85.7480 - val_loss: 88.3309\n",
            "Epoch 92/100\n",
            "345596/345596 [==============================] - 3s 9us/step - loss: 85.4173 - val_loss: 87.4978\n",
            "Epoch 93/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 85.4193 - val_loss: 87.4847\n",
            "Epoch 94/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 85.4058 - val_loss: 86.3113\n",
            "Epoch 95/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 85.1544 - val_loss: 86.0476\n",
            "Epoch 96/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 85.4325 - val_loss: 86.0201\n",
            "Epoch 97/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 85.1409 - val_loss: 88.8537\n",
            "Epoch 98/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 84.8793 - val_loss: 86.1281\n",
            "Epoch 99/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 84.7256 - val_loss: 86.8524\n",
            "Epoch 100/100\n",
            "345596/345596 [==============================] - 3s 8us/step - loss: 84.9254 - val_loss: 86.7006\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hq6SbNklpR4W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save model and weights\n",
        "\n",
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(path/'keras/keras_model.json', 'w') as json_file:\n",
        "    json_file.write(model_json)\n",
        "    \n",
        "# serialize weights to HDF5\n",
        "model.save_weights(path/'keras/keras_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "it726xME7GZr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "31053c20-af25-439d-a052-d4a6bc9cc3f6"
      },
      "source": [
        "# reload json and create model\n",
        "json_open = open(path/'keras/keras_model.json', 'r')\n",
        "json_file = json_open.read()\n",
        "json_open.close()\n",
        "model = model_from_json(json_file)\n",
        "\n",
        "# load saved weights into model\n",
        "model.load_weights(path/'keras/keras_model.h5')\n",
        "\n",
        "# make a prediction using test data\n",
        "test_sample = np.array([xTest[0,]]) # need this to set input to expected dimension\n",
        "pred = model.predict(test_sample).ravel()[0]\n",
        "targ = yTest[0]\n",
        "print('mean_travel_time prediction: {}'.format(round(pred.astype('float'),2)))\n",
        "print('mean_travel_time target:     {}'.format(targ))"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean_travel_time prediction: 3003.44\n",
            "mean_travel_time target:     3021.64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yxoxRJq_wn0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0f73c668-e1f7-4548-c2b2-8169b6325754"
      },
      "source": [
        "# evaluate model on test set\n",
        "model.compile(loss='mean_absolute_error', optimizer=Adadelta(), metrics=['mean_absolute_error'])\n",
        "mae_keras = model.evaluate(xTest, yTest, verbose=0)[0]\n",
        "\n",
        "print('Mean Absolute Error using keras neural net: {}'.format(round(mae_keras, 2)))"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Absolute Error using keras neural net: 86.92\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osnr5PQvFE5T",
        "colab_type": "text"
      },
      "source": [
        "Given the performance of the Fastai model, the Keras model likely has room for improvement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agCcET2gFbX6",
        "colab_type": "text"
      },
      "source": [
        "### Summary of model performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APnGTQHSFjMU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "8d8db6a6-883a-435a-d7f0-8fd34e1ca900"
      },
      "source": [
        "print('Mean Average Errors:\\n')\n",
        "print('{:<30} {:>10}'.format('Median prediction' ,round(mae_med, 2)))\n",
        "print('{:<30} {:>10}'.format('Linear regression', round(mae_lr, 2)))\n",
        "print('{:<30} {:>10}'.format('Random forest regression', round(mae_rf_best, 2)))\n",
        "print('{:<30} {:>10}'.format('Neural Network (Fastai)', round(mae_nn, 2)))\n",
        "print('{:<30} {:>10}'.format('Neural Network (Keras)', round(mae_keras, 2)))"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Average Errors:\n",
            "\n",
            "Median prediction                  446.02\n",
            "Linear regression                  166.03\n",
            "Random forest regression            89.56\n",
            "Neural Network (Fastai)             37.98\n",
            "Neural Network (Keras)              86.92\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1G5yjoCL3WW",
        "colab_type": "text"
      },
      "source": [
        "The errors for each these models could be further reduced by additional hyperparameter tuning. However, the Fastai model shows the most promise, given its simplicity and fast training. Using mostly default parameters, it fits with 56% lower MAE on test data than the Keras model."
      ]
    }
  ]
}